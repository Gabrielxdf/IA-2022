{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avaliação - Regressão usando MLP\n",
    "## Inferir custos médicos do plano de saúde a partir do arquivo insurance.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregamento dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance = pd.read_csv(Path('insurance.csv'))\n",
    "insurance.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparação dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#função para reverter o pandas.get_dummies()\n",
    "def undummify(df, prefix_sep=\"_\"):\n",
    "    cols2collapse = {\n",
    "        item.split(prefix_sep)[0]: (prefix_sep in item) for item in df.columns\n",
    "    }\n",
    "    series_list = []\n",
    "    for col, needs_to_collapse in cols2collapse.items():\n",
    "        if needs_to_collapse:\n",
    "            undummified = (\n",
    "                df.filter(like=col)\n",
    "                .idxmax(axis=1)\n",
    "                .apply(lambda x: x.split(prefix_sep, maxsplit=1)[1])\n",
    "                .rename(col)\n",
    "            )\n",
    "            series_list.append(undummified)\n",
    "        else:\n",
    "            series_list.append(df[col])\n",
    "    undummified_df = pd.concat(series_list, axis=1)\n",
    "    return undummified_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_encoding = pd.get_dummies(insurance[['sex', 'region', 'smoker']])\n",
    "one_hot_encoding.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance = insurance.drop(['sex', 'region', 'smoker'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance = pd.concat([insurance, one_hot_encoding], axis=1)\n",
    "insurance.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance.corr()['charges'].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = train_test_split(insurance, test_size=0.2)\n",
    "print(len(train_set), \"train +\", len(test_set), \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train, y_test = train_set['charges'], test_set['charges']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test = train_set.drop(['charges'], axis=1), test_set.drop(['charges'], axis=1)\n",
    "x_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinamento e avaliação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "def plot_learning_curves_random_forest(X, y, max_depth):\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2)\n",
    "    train_errors, val_errors = [], []\n",
    "    for max in range(1, max_depth):\n",
    "        model = RandomForestRegressor(n_estimators=500, random_state=42, max_depth=max, n_jobs=-1)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_train_predict = model.predict(X_train)\n",
    "        y_val_predict = model.predict(X_val)\n",
    "        train_errors.append(mean_squared_error(y_train_predict, y_train))\n",
    "        val_errors.append(mean_squared_error(y_val_predict, y_val))\n",
    "    plt.xlabel(\"Profundidade máxima das árvore\")\n",
    "    plt.ylabel(\"RMSE\")\n",
    "    plt.plot(np.sqrt(train_errors), \"r-\", linewidth=2, label=\"Conjunto de treinamento\")  \n",
    "    plt.plot(np.sqrt(val_errors), \"b-\", linewidth=2, label=\"Conjunto de validação\")\n",
    "    plt.legend()\n",
    "\n",
    "plot_learning_curves_random_forest(pd.concat([x_train, x_test]), pd.concat([y_train, y_test]), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = RandomForestRegressor(n_estimators=500, max_depth=4, random_state=42, n_jobs=-1)\n",
    "regressor.fit(x_train, y_train)\n",
    "resultado_random_forest_train = regressor.predict(x_train)\n",
    "resultado_random_forest_test = regressor.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#K-fold cross validation\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits=3)\n",
    "resultados_mse_train = []\n",
    "resultados_mae_train = []\n",
    "resultados_r2_train = []\n",
    "resultados_mse_test = []\n",
    "resultados_mae_test = []\n",
    "resultados_r2_test = []\n",
    "x_full = pd.concat([x_train, x_test])\n",
    "y_full = pd.concat([y_train, y_test])\n",
    "\n",
    "for train_index, test_index in kf.split(x_full):\n",
    "    x_train_fold, x_test_fold = x_full.iloc[train_index], x_full.iloc[test_index]\n",
    "    y_train_fold, y_test_fold = y_full.iloc[train_index], y_full.iloc[test_index]\n",
    "\n",
    "    \n",
    "    regressor.fit(x_train_fold, y_train_fold)\n",
    "    resultado_random_forest_train_k = regressor.predict(x_train_fold)\n",
    "    resultado_random_forest_test_k = regressor.predict(x_test_fold)\n",
    "    resultados_mse_train.append(mean_squared_error(y_train_fold, resultado_random_forest_train_k))\n",
    "    resultados_mae_train.append(mean_absolute_error(y_train_fold, resultado_random_forest_train_k))\n",
    "    resultados_r2_train.append(r2_score(y_train_fold, resultado_random_forest_train_k))\n",
    "    resultados_mse_test.append(mean_squared_error(y_test_fold, resultado_random_forest_test_k))\n",
    "    resultados_mae_test.append(mean_absolute_error(y_test_fold, resultado_random_forest_test_k))\n",
    "    resultados_r2_test.append(r2_score(y_test_fold, resultado_random_forest_test_k))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mean\n",
    "\n",
    "print('MSE, MAE E R2 NO TREINO - RANDOM FOREST')\n",
    "print(mean_squared_error(y_train, resultado_random_forest_train))\n",
    "print(mean_absolute_error(y_train, resultado_random_forest_train))\n",
    "print(r2_score(y_train, resultado_random_forest_train))\n",
    "\n",
    "print('MSE, MAE E R2 NO TESTE - RANDOM FOREST')\n",
    "print(mean_squared_error(y_test, resultado_random_forest_test))\n",
    "print(mean_absolute_error(y_test, resultado_random_forest_test))\n",
    "print(r2_score(y_test, resultado_random_forest_test))\n",
    "\n",
    "print('MSE, MAE E R2 COM K_FOLD_CROSS_VALIDATION NO TREINO - RANDOM FOREST')\n",
    "print(mean(resultados_mse_train))\n",
    "print(mean(resultados_mae_train))\n",
    "print(mean(resultados_r2_train))\n",
    "\n",
    "print('MSE, MAE E R2 COM K_FOLD_CROSS_VALIDATION NO TESTE - RANDOM FOREST')\n",
    "print(mean(resultados_mse_test))\n",
    "print(mean(resultados_mae_test))\n",
    "print(mean(resultados_r2_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rede Neural com TensorFlow e Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "keras.layers.Dense(12, activation=\"elu\", kernel_initializer=keras.initializers.HeNormal(seed=42), input_shape=[11]),\n",
    "keras.layers.BatchNormalization(),\n",
    "keras.layers.Dropout(rate=0.10),\n",
    "keras.layers.Dense(12, activation=\"elu\", kernel_initializer=keras.initializers.HeNormal(seed=42)),\n",
    "keras.layers.BatchNormalization(),\n",
    "keras.layers.Dropout(rate=0.10),\n",
    "keras.layers.Dense(12, activation=\"elu\", kernel_initializer=keras.initializers.HeNormal(seed=42)),\n",
    "keras.layers.BatchNormalization(),\n",
    "keras.layers.Dropout(rate=0.10),\n",
    "keras.layers.Dense(12, activation=\"elu\", kernel_initializer=keras.initializers.HeNormal(seed=42)),\n",
    "keras.layers.BatchNormalization(),\n",
    "keras.layers.Dropout(rate=0.10),\n",
    "keras.layers.Dense(12, activation=\"elu\", kernel_initializer=keras.initializers.HeNormal(seed=42)),\n",
    "keras.layers.BatchNormalization(),\n",
    "keras.layers.Dropout(rate=0.10),\n",
    "keras.layers.Dense(12, activation=\"elu\", kernel_initializer=keras.initializers.HeNormal(seed=42)),\n",
    "keras.layers.BatchNormalization(),\n",
    "keras.layers.Dropout(rate=0.10),\n",
    "keras.layers.Dense(12, activation=\"elu\", kernel_initializer=keras.initializers.HeNormal(seed=42)),\n",
    "keras.layers.BatchNormalization(),\n",
    "keras.layers.Dropout(rate=0.10),\n",
    "keras.layers.Dense(12, activation=\"elu\", kernel_initializer=keras.initializers.HeNormal(seed=42)),\n",
    "keras.layers.BatchNormalization(),\n",
    "keras.layers.Dropout(rate=0.10),\n",
    "keras.layers.Dense(12, activation=\"elu\", kernel_initializer=keras.initializers.HeNormal(seed=42)),\n",
    "keras.layers.BatchNormalization(),\n",
    "keras.layers.Dropout(rate=0.10),\n",
    "keras.layers.Dense(12, activation=\"elu\", kernel_initializer=keras.initializers.HeNormal(seed=42)),\n",
    "keras.layers.BatchNormalization(),\n",
    "keras.layers.Dropout(rate=0.10),\n",
    "keras.layers.Dense(12, activation=\"elu\", kernel_initializer=keras.initializers.HeNormal(seed=42)),\n",
    "keras.layers.BatchNormalization(),\n",
    "keras.layers.Dropout(rate=0.10),\n",
    "keras.layers.Dense(12, activation=\"elu\", kernel_initializer=keras.initializers.HeNormal(seed=42)),\n",
    "keras.layers.Dropout(rate=0.10),\n",
    "keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.utils.plot_model(model, to_file = \"model.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Depois de construir o modelo preciso compilar\n",
    "#Na fase de compilação, define-se, por exemplo\n",
    "#a função de perda, o otimizador, as métricas para serem calculadas  durante o treinamento e validação e etc\n",
    "\n",
    "model.compile(loss=\"mae\",\n",
    "optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learning scheduler\n",
    "def exponential_decay(lr0, s):\n",
    "    def exponential_decay_fn(epoch):\n",
    "        return lr0 * 0.1**(epoch / s)\n",
    "    return exponential_decay_fn\n",
    "\n",
    "def power_decay(lr0, s, c=1):\n",
    "    def power_decay_fn(epoch):\n",
    "        return lr0 / (1 + (epoch/s))**c\n",
    "    return power_decay_fn\n",
    "\n",
    "exponential_decay = exponential_decay(0.1, 20)\n",
    "power_decay = power_decay(0.1, 20)\n",
    "learning_rate_scheduler = keras.callbacks.LearningRateScheduler(power_decay, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#K-fold cross validation\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits=3)\n",
    "resultados_mse_train = []\n",
    "resultados_mae_train = []\n",
    "resultados_r2_train = []\n",
    "resultados_mse_test = []\n",
    "resultados_mae_test = []\n",
    "resultados_r2_test = []\n",
    "resultados_history = []\n",
    "x_full = pd.concat([x_train, x_test])\n",
    "y_full = pd.concat([y_train, y_test])\n",
    "\n",
    "for train_index, test_index in kf.split(x_full):\n",
    "    x_train_fold, x_test_fold = x_full.iloc[train_index], x_full.iloc[test_index]\n",
    "    y_train_fold, y_test_fold = y_full.iloc[train_index], y_full.iloc[test_index]\n",
    "\n",
    "    resultados_history.append(model.fit(x_train_fold, y_train_fold, epochs=500, validation_data=(x_test_fold, y_test_fold),\n",
    "    callbacks=[keras.callbacks.EarlyStopping(patience=20, restore_best_weights=True)]))\n",
    "    resultado_mlp_train = model.predict(x_train_fold)\n",
    "    resultado_mlp_test = model.predict(x_test_fold)\n",
    "    resultados_mse_train.append(mean_squared_error(y_train_fold, resultado_mlp_train))\n",
    "    resultados_mae_train.append(mean_absolute_error(y_train_fold, resultado_mlp_train))\n",
    "    resultados_r2_train.append(r2_score(y_train_fold, resultado_mlp_train))\n",
    "    resultados_mse_test.append(mean_squared_error(y_test_fold, resultado_mlp_test))\n",
    "    resultados_mae_test.append(mean_absolute_error(y_test_fold, resultado_mlp_test))\n",
    "    resultados_r2_test.append(r2_score(y_test_fold, resultado_mlp_test))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x_train, y_train, epochs=500, validation_data=(x_test, y_test),\n",
    "callbacks=[keras.callbacks.EarlyStopping(patience=20, restore_best_weights=True)])\n",
    "#callbacks=[keras.callbacks.EarlyStopping(patience=25), learning_rate_scheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mean\n",
    "resultado_mlp = model.predict(x_train)\n",
    "resultado_mlp2 = model.predict(x_test)\n",
    "\n",
    "print('MSE, MAE E R2 NO TREINO - MLP')\n",
    "print(mean_squared_error(y_train, resultado_mlp))\n",
    "print(mean_absolute_error(y_train, resultado_mlp))\n",
    "print(r2_score(y_train, resultado_mlp))\n",
    "\n",
    "print('MSE, MAE E R2 NO TESTE - MLP')\n",
    "print(mean_squared_error(y_test, resultado_mlp2))\n",
    "print(mean_absolute_error(y_test, resultado_mlp2))\n",
    "print(r2_score(y_test, resultado_mlp2))\n",
    "\n",
    "print('MSE, MAE E R2 COM MLP COM K_FOLD_CROSS_VALIDATION NO TREINO - MLP')\n",
    "print(mean(resultados_mse_train))\n",
    "print(mean(resultados_mae_train))\n",
    "print(mean(resultados_r2_train))\n",
    "\n",
    "print('MSE, MAE E R2 COM MLP COM K_FOLD_CROSS_VALIDATION NO TESTE - MLP')\n",
    "print(mean(resultados_mse_test))\n",
    "print(mean(resultados_mae_test))\n",
    "print(mean(resultados_r2_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Posso fazer curvas de aprendizado com o histórico do treinamento da rede neural\n",
    "#history.history.pop('lr')\n",
    "pd.DataFrame(history.history).plot(figsize=(10, 6))\n",
    "plt.grid(True)\n",
    "plt.title(\"Sem K-Fold\")\n",
    "plt.xlabel(\"Épocas\")\n",
    "plt.ylabel(\"MAE\")\n",
    "plt.gca()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define number of rows and columns for subplots\n",
    "nrow=3\n",
    "ncol=1\n",
    "\n",
    "# make a list of all dataframes \n",
    "df_list = [pd.DataFrame(resultados_history[0].history),\n",
    "pd.DataFrame(resultados_history[1].history), pd.DataFrame(resultados_history[2].history)]\n",
    "fig, axes = plt.subplots(nrow, ncol, sharey=True)\n",
    "plt.close()\n",
    "# plot counter\n",
    "count=0\n",
    "for r in range(nrow):\n",
    "    for c in range(ncol):\n",
    "        df_list[count].plot(figsize=(10, 6))\n",
    "        plt.grid(True)\n",
    "        plt.title(f\"Com K-Fold, Split {count}\")\n",
    "        plt.xlabel(\"Épocas\")\n",
    "        plt.ylabel(\"MAE\")\n",
    "        plt.gca()\n",
    "        plt.show()\n",
    "        count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_hidden=12, n_neurons=12, learning_rate=3e-3, input_shape=[11], optimizer = \"nadam\"):\n",
    "    model = keras.models.Sequential()\n",
    "    options = {\"input_shape\": input_shape}\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation=\"elu\", **options))\n",
    "        options = {}\n",
    "    model.add(keras.layers.Dense(1, **options))\n",
    "    model.compile(loss=\"mse\", optimizer=optimizer)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scikeras.wrappers import KerasRegressor\n",
    "\n",
    "#keras_reg = KerasRegressor(build_model, n_hidden=12, n_neurons=12, learning_rate=3e-3, input_shape=[11])\n",
    "keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)\n",
    "#history = keras_reg.fit(x_train, y_train, epochs=300, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import reciprocal\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "param_distribs = {\n",
    "\"n_hidden\": np.arange(1, 15),\n",
    "\"n_neurons\": np.arange(1, 15),\n",
    "\"optimizer\": [\"Adagrad\", \"RMSprop\", \"Adam\", \"Nadam\", \"Adamax\"],\n",
    "#\"learning_rate\": reciprocal(3e-4, 3e-2),\n",
    "#\"learning_rate\": reciprocal(3e-4, 3e-2).rvs(1000).tolist(),\n",
    "#\"learning_rate\": [0.001, 0.01, 0.1],\n",
    "}\n",
    "rnd_search_cv = GridSearchCV(keras_reg, param_distribs, cv=3, n_jobs=-1, scoring=\"r2\")\n",
    "rnd_search_cv.fit(x_train, y_train, epochs=500,\n",
    "validation_data=(x_test, y_test),\n",
    "callbacks=[keras.callbacks.EarlyStopping(patience=20, verbose=1, restore_best_weights=True)], verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Melhores parâmetros: {rnd_search_cv.best_params_}\")\n",
    "print(f\"Melhor score: {rnd_search_cv.best_score_}\")\n",
    "model = rnd_search_cv.best_estimator_.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado_mlp = model.predict(x_train)\n",
    "resultado_mlp2 = model.predict(x_test)\n",
    "\n",
    "print('MSE, MAE E R2 NO TREINO - MLP GRID SEARCH')\n",
    "print(mean_squared_error(y_train, resultado_mlp))\n",
    "print(mean_absolute_error(y_train, resultado_mlp))\n",
    "print(r2_score(y_train, resultado_mlp))\n",
    "\n",
    "resultado_mlp = model.predict(x_test)\n",
    "\n",
    "print('MSE, MAE E R2 NO TESTE - MLP GRID SEARCH')\n",
    "print(mean_squared_error(y_test, resultado_mlp2))\n",
    "print(mean_absolute_error(y_test, resultado_mlp2))\n",
    "print(r2_score(y_test, resultado_mlp2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "cb1c843bd532218b5b3145213f753416a791e8d8e9251cccf1adcef2f98ce6f8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
