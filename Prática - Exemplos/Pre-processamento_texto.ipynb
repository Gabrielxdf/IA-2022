{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from unidecode import unidecode\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vamos entender os 3 passos de pré-processamento de texto de forma rápida! [ç, ã, ê, ü, $, ö]\n"
     ]
    }
   ],
   "source": [
    "# Exemplo\n",
    "example = 'Vamos entender os 3 passos de pré-processamento de texto de forma rápida! [ç, ã, ê, ü, $, ö]'\n",
    "print(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vamos entender os 3 passos de pré-processamento de texto de forma rápida! [ç, ã, ê, ü, $, ö]\n"
     ]
    }
   ],
   "source": [
    "# Lowercase\n",
    "\n",
    "example = example.lower()\n",
    "print(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vamos entender os 3 passos de pré processamento de texto de forma rápida   ç  ã  ê  ü     ö \n"
     ]
    }
   ],
   "source": [
    "# Remoção de pontuação e símbolos\n",
    "\n",
    "# Tabela de pontuação\n",
    "punctuation = string.punctuation\n",
    "# Criar tabela de tradução que susbstituirá toda ponutação por um espaço em branco\n",
    "trantab = str.maketrans(punctuation, len(punctuation)*' ')\n",
    "# Traduzir nosso exemplo\n",
    "example = example.translate(trantab)\n",
    "\n",
    "print(example)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vamos entender os 3 passos de pre processamento de texto de forma rapida   c  a  e  u     ö \n",
      "vamos entender os 3 passos de pre processamento de texto de forma rapida   c  a  e  u     o \n"
     ]
    }
   ],
   "source": [
    "# Remover caracteres especiais (acentos e afins)\n",
    "\n",
    "# Método 1\n",
    "def remove_special_chars(input_text):\n",
    "    input_text = re.sub(u'[áãâà]', 'a', input_text)\n",
    "    input_text = re.sub(u'[éèê]', 'e', input_text)\n",
    "    input_text = re.sub(u'[íì]', 'i', input_text)\n",
    "    input_text = re.sub(u'[óõôò]', 'o', input_text)\n",
    "    input_text = re.sub(u'[úùü]', 'u', input_text)\n",
    "    input_text = re.sub(u'[ç]', 'c', input_text)\n",
    "    return input_text\n",
    "\n",
    "print(remove_special_chars(example))\n",
    "\n",
    "\n",
    "# Método 2\n",
    "example = unidecode(example)\n",
    "print(example)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vamos entender os  passos de pre processamento de texto de forma rapida   c  a  e  u     o \n"
     ]
    }
   ],
   "source": [
    "# Remover dígitos\n",
    "\n",
    "def remove_digits(input_text):\n",
    "    import re\n",
    "    return re.sub('\\d+', '', input_text)\n",
    "\n",
    "example = remove_digits(example)\n",
    "print(example)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vamos entender passos pre processamento texto forma rapida\n"
     ]
    }
   ],
   "source": [
    "# Remover stopwords\n",
    "\n",
    "try:\n",
    "    stopwords_list = stopwords.words('portuguese')\n",
    "except:\n",
    "    nltk.download('stopwords')\n",
    "    stopwords_list = stopwords.words('portuguese')\n",
    "\n",
    "def remove_stopwords(input_text, stopwords_list):\n",
    "    words = input_text.split()\n",
    "    clean_words = [word for word in words if (word not in stopwords_list) and len(word) > 1]\n",
    "    return \" \".join(clean_words)\n",
    "\n",
    "example = remove_stopwords(example, stopwords_list)\n",
    "print(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vamo entend passo pre processamento texto forma rapida\n"
     ]
    }
   ],
   "source": [
    "# Radicalização\n",
    "\n",
    "def stemming(input_text):\n",
    "    porter = PorterStemmer()\n",
    "    words = input_text.split()\n",
    "    stemmed_words = [porter.stem(word) for word in words]\n",
    "    return \" \".join(stemmed_words)\n",
    "example = stemming(example)\n",
    "print(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['vamo entend passo pre processamento texto forma rapida vamo',\n",
       "       'vamo pular psicina'], dtype='<U59')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# O TF-IDF espera um iterable como corpus, logo nosso exemplo precisa se tornar um array ou lista\n",
    "\n",
    "example = np.array(\n",
    "    [\n",
    "        'vamo entend passo pre processamento texto forma rapida vamo',\n",
    "        'vamo pular psicina'\n",
    "    ]\n",
    ")\n",
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     entend     forma     passo       pre  processamento   psicina     pular  \\\n",
      "0  0.332872  0.332872  0.332872  0.332872       0.332872  0.000000  0.000000   \n",
      "1  0.000000  0.000000  0.000000  0.000000       0.000000  0.631667  0.631667   \n",
      "\n",
      "     rapida     texto      vamo  \n",
      "0  0.332872  0.332872  0.473682  \n",
      "1  0.000000  0.000000  0.449436  \n"
     ]
    }
   ],
   "source": [
    "# O TF-IDF\n",
    "\n",
    "# Instanciar o vetorizador do sklearn\n",
    "tfv = TfidfVectorizer()\n",
    "# Ajustar os pesos e fazer a transformação do corpus para a representação TF-IDF\n",
    "tfidf = tfv.fit_transform(example)\n",
    "\n",
    "\n",
    "tfidf = pd.DataFrame.sparse.from_spmatrix(tfidf, columns=tfv.get_feature_names())\n",
    "print(tfidf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTANTE\n",
    "# O TfidfVectorizer() se ajusta ao corpus, logo, deve ser ajustado nos dados de treino e no momento de codificar os dados de teste ou na inferência\n",
    "# usar apenas a chamada tfv.transform(test)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fb2241dd84d24fce0f6d13cd3007375d8775345fba65719499b77c7a197c874f"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
